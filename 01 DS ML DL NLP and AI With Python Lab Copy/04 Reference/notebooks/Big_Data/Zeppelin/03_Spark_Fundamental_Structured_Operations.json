{"paragraphs":[{"title":"Objectives","text":"%md\n\nIn this notebook, you will learn the fundamental DataFrame operations. There are five lessons. Each will breakdown a fundamental DataFrame operation.\n\n**Lesson 1:** Schema\n\n**Lesson 2:** Columns \n\n**Lesson 3:** Rows\n\n**Lesson 4:** Repartition and Coalesce\n\n**Lesson 5:** Creating a DataFrame\n\n*Note: advanced topics like aggregations and joins will be covered separately.*","user":"anonymous","dateUpdated":"2018-05-02T14:11:14-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>In this notebook, you will learn the fundamental DataFrame operations. There are five lessons. Each will breakdown a fundamental DataFrame operation.</p>\n<p><strong>Lesson 1:</strong> Schema</p>\n<p><strong>Lesson 2:</strong> Columns </p>\n<p><strong>Lesson 3:</strong> Rows</p>\n<p><strong>Lesson 4:</strong> Repartition and Coalesce</p>\n<p><strong>Lesson 5:</strong> Creating a DataFrame</p>\n<p><em>Note: advanced topics like aggregations and joins will be covered separately.</em></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1524852743714_-1862205517","id":"20180427-131223_591358284","dateCreated":"2018-04-27T13:12:23-0500","dateStarted":"2018-05-02T14:11:14-0500","dateFinished":"2018-05-02T14:11:14-0500","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9503"},{"title":"Read Data","text":"%pyspark\n\npath = \"/Users/davidziganto/data/higgs_multi.csv\"\n\ndf = spark.read \\\n        .format(\"csv\") \\\n        .option(\"mode\", \"FAILFAST\") \\\n        .option(\"inferSchema\", \"true\") \\\n        .option(\"header\", \"false\") \\\n        .load(path)","user":"anonymous","dateUpdated":"2018-05-02T12:36:24-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525191521657_-1395579954","id":"20180501-111841_1944213525","dateCreated":"2018-05-01T11:18:41-0500","dateStarted":"2018-05-02T12:36:24-0500","dateFinished":"2018-05-02T12:38:14-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9504"},{"text":"%pyspark\n\ndf.head(2)","user":"anonymous","dateUpdated":"2018-05-02T12:38:32-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[Row(_c0=1.0, _c1=0.7675400972366333, _c2=0.0554620623588562, _c3=0.7805516123771667, _c4=0.7783055305480957, _c5=-0.8234665393829346, _c6=0.7380793690681458, _c7=-1.9319639205932617, _c8=-1.1885251998901367, _c9=0.0, _c10=0.6874330639839172, _c11=2.0234315395355225, _c12=-0.03404783084988594, _c13=0.0, _c14=0.708105206489563, _c15=0.31329843401908875, _c16=-0.6242770552635193, _c17=0.0, _c18=1.2898144721984863, _c19=-0.09290407598018646, _c20=1.7245053052902222, _c21=3.101961374282837, _c22=1.120473861694336, _c23=0.837995707988739, _c24=1.0622297525405884, _c25=0.6876048445701599, _c26=0.9390519261360168, _c27=0.8967953324317932, _c28=0.8683176636695862), Row(_c0=1.0, _c1=0.5195627808570862, _c2=0.11097828298807144, _c3=-0.6194689273834229, _c4=0.9009047150611877, _c5=0.11677631735801697, _c6=1.1231961250305176, _c7=0.4544900953769684, _c8=1.4138178825378418, _c9=0.0, _c10=0.9193472862243652, _c11=1.423122763633728, _c12=-0.332546204328537, _c13=1.1074360609054565, _c14=0.976981520652771, _c15=-0.0699162557721138, _c16=-1.6083775758743286, _c17=0.0, _c18=0.9728984236717224, _c19=1.5419279336929321, _c20=-0.6866931319236755, _c21=0.0, _c22=0.9173910617828369, _c23=0.9878050684928894, _c24=0.9918923377990723, _c25=0.6056129336357117, _c26=0.96597820520401, _c27=1.0190566778182983, _c28=0.9113413095474243)]\n"}]},"apps":[],"jobName":"paragraph_1525197417211_-1414053432","id":"20180501-125657_885098907","dateCreated":"2018-05-01T12:56:57-0500","dateStarted":"2018-05-02T12:38:32-0500","dateFinished":"2018-05-02T12:38:33-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9505"},{"text":"%md\n\n# Start of Lesson 1","user":"anonymous","dateUpdated":"2018-05-01T13:06:35-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Start of Lesson 1</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525194234757_-1417094197","id":"20180501-120354_1636770625","dateCreated":"2018-05-01T12:03:54-0500","dateStarted":"2018-05-01T13:06:35-0500","dateFinished":"2018-05-01T13:06:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9506"},{"title":"Lesson 1: Schema Overview","text":"%md\n\nUnderstanding the concept of a **schema** is important. A schema defines the column names and column types of a DataFrame. \n\nThe schema can be defined in one of two ways:\n\n1. Via data source (called *schema-on-read*)\n2. Explicity by user\n\n**Question: When should you use schema-on-read and when should you explicity provide the schema?**\n**Answer:** Using schema-on-read is usually fine for ad-hoc analysis. However, read times for CSV and JSON files can be slow and you may run into precision issues where a column really should be a *long* type but gets set as *integer*. If you want speed and precision (i.e. production environments), use an explicit schema.","user":"anonymous","dateUpdated":"2018-05-01T13:06:35-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Understanding the concept of a <strong>schema</strong> is important. A schema defines the column names and column types of a DataFrame. </p>\n<p>The schema can be defined in one of two ways:</p>\n<ol>\n  <li>Via data source (called <em>schema-on-read</em>)</li>\n  <li>Explicity by user</li>\n</ol>\n<p><strong>Question: When should you use schema-on-read and when should you explicity provide the schema?</strong><br/><strong>Answer:</strong> Using schema-on-read is usually fine for ad-hoc analysis. However, read times for CSV and JSON files can be slow and you may run into precision issues where a column really should be a <em>long</em> type but gets set as <em>integer</em>. If you want speed and precision (i.e. production environments), use an explicit schema.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525191838682_-681087043","id":"20180501-112358_2138999633","dateCreated":"2018-05-01T11:23:58-0500","dateStarted":"2018-05-01T13:06:35-0500","dateFinished":"2018-05-01T13:06:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9507"},{"title":"Lesson 1-1: Quick Look at Schema (Unformatted)","text":"%pyspark\n\nspark.read \\\n    .format(\"csv\") \\\n    .option(\"mode\", \"FAILFAST\") \\\n    .option(\"inferSchema\", \"true\") \\\n    .option(\"header\", \"false\") \\\n    .load(path) \\\n    .schema","user":"anonymous","dateUpdated":"2018-05-02T12:38:38-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"StructType(List(StructField(_c0,DoubleType,true),StructField(_c1,DoubleType,true),StructField(_c2,DoubleType,true),StructField(_c3,DoubleType,true),StructField(_c4,DoubleType,true),StructField(_c5,DoubleType,true),StructField(_c6,DoubleType,true),StructField(_c7,DoubleType,true),StructField(_c8,DoubleType,true),StructField(_c9,DoubleType,true),StructField(_c10,DoubleType,true),StructField(_c11,DoubleType,true),StructField(_c12,DoubleType,true),StructField(_c13,DoubleType,true),StructField(_c14,DoubleType,true),StructField(_c15,DoubleType,true),StructField(_c16,DoubleType,true),StructField(_c17,DoubleType,true),StructField(_c18,DoubleType,true),StructField(_c19,DoubleType,true),StructField(_c20,DoubleType,true),StructField(_c21,DoubleType,true),StructField(_c22,DoubleType,true),StructField(_c23,DoubleType,true),StructField(_c24,DoubleType,true),StructField(_c25,DoubleType,true),StructField(_c26,DoubleType,true),StructField(_c27,DoubleType,true),StructField(_c28,DoubleType,true)))\n"}]},"apps":[],"jobName":"paragraph_1525192288449_-1175028010","id":"20180501-113128_1196999665","dateCreated":"2018-05-01T11:31:28-0500","dateStarted":"2018-05-02T12:38:38-0500","dateFinished":"2018-05-02T12:39:55-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9508"},{"title":"Lesson 1-2: What Defines a Schema?","text":"%md\n\nYou may have noticed a few things in the cell above. \n\nFirst, each column is prefixed with an underscore. For example, we can see the first column is called *_c0*, the second *_c1*, and so on. \n\nSecondly, each column has a type. For example, the first column is *IntegerType* while the second is StringType. \n\nContained in the same tuple as the column name and type is a Boolean true or false. This Boolean indicates whether that particular column can contain missing or null values. \n\nNot shown here is a fourth item in the same tuple. It is optional. It allows users to store metadata about the column. This will come up again in Spark machine learning. For now we won't say much else about the metadata. \n\nYou may have also noticed each column and its corresponding information contained with the tuple are wrapped in a **StructField). A **StructField** is simply a field in Spark. \n\nLastly, you may have noticed the StructField objects wrapped in a **StructType**. In this case, the StructType is a **List**. There are other StructTypes but that's outside the scope of this tutorial.","user":"anonymous","dateUpdated":"2018-05-01T13:06:35-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>You may have noticed a few things in the cell above. </p>\n<p>First, each column is prefixed with an underscore. For example, we can see the first column is called *_c0*, the second *_c1*, and so on. </p>\n<p>Secondly, each column has a type. For example, the first column is <em>IntegerType</em> while the second is StringType. </p>\n<p>Contained in the same tuple as the column name and type is a Boolean true or false. This Boolean indicates whether that particular column can contain missing or null values. </p>\n<p>Not shown here is a fourth item in the same tuple. It is optional. It allows users to store metadata about the column. This will come up again in Spark machine learning. For now we won&rsquo;t say much else about the metadata. </p>\n<p>You may have also noticed each column and its corresponding information contained with the tuple are wrapped in a **StructField). A <strong>StructField</strong> is simply a field in Spark. </p>\n<p>Lastly, you may have noticed the StructField objects wrapped in a <strong>StructType</strong>. In this case, the StructType is a <strong>List</strong>. There are other StructTypes but that&rsquo;s outside the scope of this tutorial.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525192648524_-999497668","id":"20180501-113728_1974800092","dateCreated":"2018-05-01T11:37:28-0500","dateStarted":"2018-05-01T13:06:35-0500","dateFinished":"2018-05-01T13:06:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9509"},{"title":"Lesson 1-3: Detailed Look at Schema (Formatted)","text":"%pyspark\n\ndf.printSchema()","user":"anonymous","dateUpdated":"2018-05-02T12:40:01-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- _c0: double (nullable = true)\n |-- _c1: double (nullable = true)\n |-- _c2: double (nullable = true)\n |-- _c3: double (nullable = true)\n |-- _c4: double (nullable = true)\n |-- _c5: double (nullable = true)\n |-- _c6: double (nullable = true)\n |-- _c7: double (nullable = true)\n |-- _c8: double (nullable = true)\n |-- _c9: double (nullable = true)\n |-- _c10: double (nullable = true)\n |-- _c11: double (nullable = true)\n |-- _c12: double (nullable = true)\n |-- _c13: double (nullable = true)\n |-- _c14: double (nullable = true)\n |-- _c15: double (nullable = true)\n |-- _c16: double (nullable = true)\n |-- _c17: double (nullable = true)\n |-- _c18: double (nullable = true)\n |-- _c19: double (nullable = true)\n |-- _c20: double (nullable = true)\n |-- _c21: double (nullable = true)\n |-- _c22: double (nullable = true)\n |-- _c23: double (nullable = true)\n |-- _c24: double (nullable = true)\n |-- _c25: double (nullable = true)\n |-- _c26: double (nullable = true)\n |-- _c27: double (nullable = true)\n |-- _c28: double (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1525191525715_-1812247689","id":"20180501-111845_211262064","dateCreated":"2018-05-01T11:18:45-0500","dateStarted":"2018-05-02T12:40:01-0500","dateFinished":"2018-05-02T12:40:01-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9510"},{"title":"Lesson 1-4: Copy Schema","text":"%pyspark\n\nmySchema = df.schema\n\n# delete DF\ndel df","user":"anonymous","dateUpdated":"2018-05-02T12:40:05-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525193424320_1692878256","id":"20180501-115024_588913312","dateCreated":"2018-05-01T11:50:24-0500","dateStarted":"2018-05-02T12:40:05-0500","dateFinished":"2018-05-02T12:40:05-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9511"},{"title":"Lesson 1-4: Read Data w/Explicit Schema","text":"%pyspark\n\npath = \"/Users/davidziganto/data/higgs_multi.csv\"\n\ndf = spark.read \\\n        .format(\"csv\") \\\n        .option(\"mode\", \"FAILFAST\") \\\n        .schema(mySchema) \\\n        .load(path)","user":"anonymous","dateUpdated":"2018-05-02T12:40:08-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525192637063_-548987355","id":"20180501-113717_60604703","dateCreated":"2018-05-01T11:37:17-0500","dateStarted":"2018-05-02T12:40:08-0500","dateFinished":"2018-05-02T12:40:08-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9512"},{"title":"Lesson 1-4: Schema Read Speed","text":"%md\n\nDid you notice how much faster Spark can read the CSV files with an explicit schema?","user":"anonymous","dateUpdated":"2018-05-01T19:01:28-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Did you notice how much faster Spark can read the CSV files with an explicit schema?</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525191829318_1234962479","id":"20180501-112349_61545686","dateCreated":"2018-05-01T11:23:49-0500","dateStarted":"2018-05-01T19:01:28-0500","dateFinished":"2018-05-01T19:01:28-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9513"},{"text":"%md\n\n# End of Lesson 1","user":"anonymous","dateUpdated":"2018-05-01T13:06:35-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>End of Lesson 1</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525194246187_-670650682","id":"20180501-120406_1680055026","dateCreated":"2018-05-01T12:04:06-0500","dateStarted":"2018-05-01T13:06:35-0500","dateFinished":"2018-05-01T13:06:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9514"},{"text":"%md\n\n# Start of Lesson 2","user":"anonymous","dateUpdated":"2018-05-01T13:06:36-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Start of Lesson 2</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525194255846_203514143","id":"20180501-120415_1028894008","dateCreated":"2018-05-01T12:04:15-0500","dateStarted":"2018-05-01T13:06:36-0500","dateFinished":"2018-05-01T13:06:36-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9515"},{"title":"Lesson 2: Overview","text":"%md\n\nWe will work almost entirely with Spark DataFrames, which are comprised of columns and rows. \n\nBefore we start working with DataFrames, however, it helps to step back and understand Spark columns and rows. Knowing this will give us the necessary baseline we need to understand Spark DataFrame transformations.\n\nIf you're familiar with pandas in Python, then learning how to handle Spark columns in a DataFrame is a small logical step. You can select, manipulate, and remove columns - just like you can in pandas! These operations are known in Spark as **expressions**.","user":"anonymous","dateUpdated":"2018-05-02T12:43:15-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>We will work almost entirely with Spark DataFrames, which are comprised of columns and rows. </p>\n<p>Before we start working with DataFrames, however, it helps to step back and understand Spark columns and rows. Knowing this will give us the necessary baseline we need to understand Spark DataFrame transformations.</p>\n<p>If you&rsquo;re familiar with pandas in Python, then learning how to handle Spark columns in a DataFrame is a small logical step. You can select, manipulate, and remove columns - just like you can in pandas! These operations are known in Spark as <strong>expressions</strong>.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525194302616_811694885","id":"20180501-120502_1550608532","dateCreated":"2018-05-01T12:05:02-0500","dateStarted":"2018-05-01T13:06:36-0500","dateFinished":"2018-05-01T13:06:36-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9516"},{"title":"Lesson 2-1: Column Names of DataFrame","text":"%pyspark\n\ndf.columns","user":"anonymous","dateUpdated":"2018-05-02T12:43:21-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['_c0', '_c1', '_c2', '_c3', '_c4', '_c5', '_c6', '_c7', '_c8', '_c9', '_c10', '_c11', '_c12', '_c13', '_c14', '_c15', '_c16', '_c17', '_c18', '_c19', '_c20', '_c21', '_c22', '_c23', '_c24', '_c25', '_c26', '_c27', '_c28']\n"}]},"apps":[],"jobName":"paragraph_1525193671897_886599971","id":"20180501-115431_1015415646","dateCreated":"2018-05-01T11:54:31-0500","dateStarted":"2018-05-02T12:40:22-0500","dateFinished":"2018-05-02T12:40:22-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9517"},{"title":"Lesson 2-2: Rename Single Column","text":"%pyspark\n\ndf = df.withColumnRenamed(\"_c0\", \"target\")\ndf.head()","user":"anonymous","dateUpdated":"2018-05-02T12:40:25-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Row(target=1.0, _c1=0.7675400972366333, _c2=0.0554620623588562, _c3=0.7805516123771667, _c4=0.7783055305480957, _c5=-0.8234665393829346, _c6=0.7380793690681458, _c7=-1.9319639205932617, _c8=-1.1885251998901367, _c9=0.0, _c10=0.6874330639839172, _c11=2.0234315395355225, _c12=-0.03404783084988594, _c13=0.0, _c14=0.708105206489563, _c15=0.31329843401908875, _c16=-0.6242770552635193, _c17=0.0, _c18=1.2898144721984863, _c19=-0.09290407598018646, _c20=1.7245053052902222, _c21=3.101961374282837, _c22=1.120473861694336, _c23=0.837995707988739, _c24=1.0622297525405884, _c25=0.6876048445701599, _c26=0.9390519261360168, _c27=0.8967953324317932, _c28=0.8683176636695862)\n"}]},"apps":[],"jobName":"paragraph_1525220359625_-1209408277","id":"20180501-191919_1043855067","dateCreated":"2018-05-01T19:19:19-0500","dateStarted":"2018-05-02T12:40:25-0500","dateFinished":"2018-05-02T12:40:26-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9518"},{"title":"Technical Point","text":"%md\n\nFYI - Renaming columns does not happen inplace.","user":"anonymous","dateUpdated":"2018-05-02T12:41:09-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>FYI - Renaming columns does not happen inplace.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525282837101_256145656","id":"20180502-124037_170360172","dateCreated":"2018-05-02T12:40:37-0500","dateStarted":"2018-05-02T12:40:56-0500","dateFinished":"2018-05-02T12:40:57-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9519"},{"title":"Lesson 2-3: Renaming Multiple Columns","text":"%pyspark\n\ndf = df.toDF('target', 'lepton_pT', 'lepton_eta', 'lepton_phi', 'missing_energy_magnitude', 'missing_energy_phi', 'jet_1_pt', \\\n            'jet_1_eta', 'jet_1_phi', 'jet_1_b_tag', 'jet_2_pt', 'jet_2_eta', 'jet_2_phi', 'jet_2_b_tag', 'jet_3_pt', 'jet_3_eta', \\\n            'jet_3_phi', 'jet_3_b_tag', 'jet_4_pt', 'jet_4_eta', 'jet_4_phi', 'jet_4_b_tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', \\\n            'm_wbb', 'm_wwbb')\n            \ndf.head()","user":"anonymous","dateUpdated":"2018-05-02T12:41:13-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Row(target=1.0, lepton_pT=0.7675400972366333, lepton_eta=0.0554620623588562, lepton_phi=0.7805516123771667, missing_energy_magnitude=0.7783055305480957, missing_energy_phi=-0.8234665393829346, jet_1_pt=0.7380793690681458, jet_1_eta=-1.9319639205932617, jet_1_phi=-1.1885251998901367, jet_1_b_tag=0.0, jet_2_pt=0.6874330639839172, jet_2_eta=2.0234315395355225, jet_2_phi=-0.03404783084988594, jet_2_b_tag=0.0, jet_3_pt=0.708105206489563, jet_3_eta=0.31329843401908875, jet_3_phi=-0.6242770552635193, jet_3_b_tag=0.0, jet_4_pt=1.2898144721984863, jet_4_eta=-0.09290407598018646, jet_4_phi=1.7245053052902222, jet_4_b_tag=3.101961374282837, m_jj=1.120473861694336, m_jjj=0.837995707988739, m_lv=1.0622297525405884, m_jlv=0.6876048445701599, m_bb=0.9390519261360168, m_wbb=0.8967953324317932, m_wwbb=0.8683176636695862)\n"}]},"apps":[],"jobName":"paragraph_1525219312190_-2074407003","id":"20180501-190152_1313226597","dateCreated":"2018-05-01T19:01:52-0500","dateStarted":"2018-05-02T12:41:13-0500","dateFinished":"2018-05-02T12:41:14-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9520"},{"title":"Lesson 2-4: Slicing Column Names","text":"%pyspark\n\ndf.columns[0:20:2]","user":"anonymous","dateUpdated":"2018-05-02T12:44:41-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['target', 'lepton_eta', 'missing_energy_magnitude', 'jet_1_pt', 'jet_1_phi', 'jet_2_pt', 'jet_2_phi', 'jet_3_pt', 'jet_3_phi', 'jet_4_pt']\n"}]},"apps":[],"jobName":"paragraph_1525195595504_-1738601426","id":"20180501-122635_1208915193","dateCreated":"2018-05-01T12:26:35-0500","dateStarted":"2018-05-02T12:44:41-0500","dateFinished":"2018-05-02T12:44:41-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9521"},{"title":"Lesson 2-5: Select Single Column","text":"%pyspark\n\ndf.select(\"lepton_eta\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T12:44:44-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+--------------------+\n|          lepton_eta|\n+--------------------+\n|  0.0554620623588562|\n| 0.11097828298807144|\n|  0.8599602580070496|\n|-0.00200209324248...|\n|  0.8667780160903931|\n+--------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525282883069_1200780827","id":"20180502-124123_651190732","dateCreated":"2018-05-02T12:41:23-0500","dateStarted":"2018-05-02T12:44:44-0500","dateFinished":"2018-05-02T12:44:44-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9522"},{"title":"Lesson 2-6: Select Multiple Columns","text":"%pyspark\n\ndf.select(\"target\", \"lepton_pT\", \"lepton_eta\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T13:09:20-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------------------+--------------------+\n|target|         lepton_pT|          lepton_eta|\n+------+------------------+--------------------+\n|   1.0|0.7675400972366333|  0.0554620623588562|\n|   1.0|0.5195627808570862| 0.11097828298807144|\n|   1.0|1.0063670873641968|  0.8599602580070496|\n|   1.0|1.4637067317962646|-0.00200209324248...|\n|   0.0|1.7219325304031372|  0.8667780160903931|\n+------+------------------+--------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525220711357_-1162010831","id":"20180501-192511_96947150","dateCreated":"2018-05-01T19:25:11-0500","dateStarted":"2018-05-02T12:44:46-0500","dateFinished":"2018-05-02T12:44:46-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9523"},{"title":"Lesson 2-7: Other Ways to Select Columns","text":"%pyspark\n\nfrom pyspark.sql.functions import expr, col, column\n\ndf.select(\n    expr(\"target\"),\n    col(\"lepton_pT\"),\n    column(\"lepton_eta\")) \\\n    .show(5)","user":"anonymous","dateUpdated":"2018-05-02T12:46:54-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------------------+--------------------+\n|target|         lepton_pT|          lepton_eta|\n+------+------------------+--------------------+\n|   1.0|0.7675400972366333|  0.0554620623588562|\n|   1.0|0.5195627808570862| 0.11097828298807144|\n|   1.0|1.0063670873641968|  0.8599602580070496|\n|   1.0|1.4637067317962646|-0.00200209324248...|\n|   0.0|1.7219325304031372|  0.8667780160903931|\n+------+------------------+--------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525283134060_-753421778","id":"20180502-124534_1007450697","dateCreated":"2018-05-02T12:45:34-0500","dateStarted":"2018-05-02T12:46:54-0500","dateFinished":"2018-05-02T12:46:54-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9524"},{"title":"Lesson 2-8: More on expr","text":"%md\n\nThe *expr* method from **pyspark.sql.functions** is powerful. Let's see some examples about why that is.","user":"anonymous","dateUpdated":"2018-05-02T12:49:40-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","title":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>The <em>expr</em> method from <strong>pyspark.sql.functions</strong> is powerful. Let&rsquo;s see some examples about why that is.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525283307432_-1628311773","id":"20180502-124827_379019381","dateCreated":"2018-05-02T12:48:27-0500","dateStarted":"2018-05-02T12:49:40-0500","dateFinished":"2018-05-02T12:49:40-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9525"},{"title":"Lesson 2-8-1: expr to alias (v1)","text":"%pyspark\n\ndf.select(expr(\"target as thing_to_predict\")).show(5)","user":"anonymous","dateUpdated":"2018-05-02T12:51:43-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+\n|thing_to_predict|\n+----------------+\n|             1.0|\n|             1.0|\n|             1.0|\n|             1.0|\n|             0.0|\n+----------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525283242730_2128163594","id":"20180502-124722_875765899","dateCreated":"2018-05-02T12:47:22-0500","dateStarted":"2018-05-02T12:51:08-0500","dateFinished":"2018-05-02T12:51:08-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9526"},{"title":"Lesson 2-8-1: expr to alias (v2)","text":"%pyspark\n df.select(expr(\"target\").alias(\"thing_to_predict\")).show(5)","user":"anonymous","dateUpdated":"2018-05-02T12:53:27-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+\n|thing_to_predict|\n+----------------+\n|             1.0|\n|             1.0|\n|             1.0|\n|             1.0|\n|             0.0|\n+----------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525283498960_-183070666","id":"20180502-125138_1796268494","dateCreated":"2018-05-02T12:51:38-0500","dateStarted":"2018-05-02T12:53:07-0500","dateFinished":"2018-05-02T12:53:07-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9527"},{"text":"%md\n\nThere's a shorthand way to deal with *select* and *expr*. Use *selectExpr* instead. Let's see an example.","user":"anonymous","dateUpdated":"2018-05-02T12:55:53-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>There&rsquo;s a shorthand way to deal with <em>select</em> and <em>expr</em>. Use <em>selectExpr</em> instead. Let&rsquo;s see an example.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525283720598_1552637247","id":"20180502-125520_954087038","dateCreated":"2018-05-02T12:55:20-0500","dateStarted":"2018-05-02T12:55:53-0500","dateFinished":"2018-05-02T12:55:53-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9528"},{"title":"Lesson 2-8-2: selectExpr (alias column name)","text":"%pyspark\n\n# simplified version of 2-8-1 (v1)\ndf.selectExpr(\"target as thing_to_predict\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T13:13:14-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------------+\n|thing_to_predict|\n+----------------+\n|             1.0|\n|             1.0|\n|             1.0|\n|             1.0|\n|             0.0|\n+----------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525283667777_254971152","id":"20180502-125427_148314412","dateCreated":"2018-05-02T12:54:27-0500","dateStarted":"2018-05-02T12:56:55-0500","dateFinished":"2018-05-02T12:56:55-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9529"},{"title":"Lesson 2-8-3: selectExpr (class balance)","text":"%pyspark\n\ndf.selectExpr(\"avg(target) as positive_class_proportion\").show()","user":"anonymous","dateUpdated":"2018-05-02T13:13:03-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+-------------------------+\n|positive_class_proportion|\n+-------------------------+\n|       0.5299202727272727|\n+-------------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1525283850857_1808344421","id":"20180502-125730_2077888977","dateCreated":"2018-05-02T12:57:30-0500","dateStarted":"2018-05-02T13:03:39-0500","dateFinished":"2018-05-02T13:03:58-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9530"},{"title":"Lesson 2-8-3: Add Column of 1s","text":"%pyspark\n\nfrom pyspark.sql.functions import lit\n\ndf = df.withColumn(\"ones\", lit(1))\n\ndf.select(\"target\", \"lepton_pT\", \"ones\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T13:10:09-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525284267937_1045986640","id":"20180502-130427_1705744375","dateCreated":"2018-05-02T13:04:27-0500","dateStarted":"2018-05-02T13:08:28-0500","dateFinished":"2018-05-02T13:08:28-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9531"},{"title":"Lesson 2-8-4: Drop Column(s)","text":"%pyspark\n\n# drop multiple by adding more names\ndf = df.drop(\"ones\")\n\ndf.columns","user":"anonymous","dateUpdated":"2018-05-02T13:13:40-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['target', 'lepton_pT', 'lepton_eta', 'lepton_phi', 'missing_energy_magnitude', 'missing_energy_phi', 'jet_1_pt', 'jet_1_eta', 'jet_1_phi', 'jet_1_b_tag', 'jet_2_pt', 'jet_2_eta', 'jet_2_phi', 'jet_2_b_tag', 'jet_3_pt', 'jet_3_eta', 'jet_3_phi', 'jet_3_b_tag', 'jet_4_pt', 'jet_4_eta', 'jet_4_phi', 'jet_4_b_tag', 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']\n"}]},"apps":[],"jobName":"paragraph_1525284499566_684244408","id":"20180502-130819_812478718","dateCreated":"2018-05-02T13:08:19-0500","dateStarted":"2018-05-02T13:11:30-0500","dateFinished":"2018-05-02T13:11:30-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9532"},{"title":"Lesson 2-9: Spark is Case Insensitive by Default","text":"%pyspark\n\ndf.select('M_WBB').show(5)","user":"anonymous","dateUpdated":"2018-05-02T13:16:41-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------------+\n|             M_WBB|\n+------------------+\n|0.8967953324317932|\n|1.0190566778182983|\n|0.9488229751586914|\n| 1.049148440361023|\n| 1.319687843322754|\n+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525284851802_1503296551","id":"20180502-131411_463704721","dateCreated":"2018-05-02T13:14:11-0500","dateStarted":"2018-05-02T13:14:25-0500","dateFinished":"2018-05-02T13:14:25-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9533"},{"title":"Lesson 2-10: Change Column's Type","text":"%pyspark\n\ndf = df.withColumn(\"new_column\", col(\"target\").cast(\"integer\"))","user":"anonymous","dateUpdated":"2018-05-02T13:19:30-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1525284894105_1158586728","id":"20180502-131454_259081333","dateCreated":"2018-05-02T13:14:54-0500","dateStarted":"2018-05-02T13:19:30-0500","dateFinished":"2018-05-02T13:19:30-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9534"},{"title":"Lesson 2-10: See Results of Cast","text":"%pyspark\n\ndf.select(\"target\", \"new_column\").show(5)\ndf.printSchema()","user":"anonymous","dateUpdated":"2018-05-02T13:20:58-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+----------+\n|target|new_column|\n+------+----------+\n|   1.0|         1|\n|   1.0|         1|\n|   1.0|         1|\n|   1.0|         1|\n|   0.0|         0|\n+------+----------+\nonly showing top 5 rows\n\nroot\n |-- target: double (nullable = true)\n |-- lepton_pT: double (nullable = true)\n |-- lepton_eta: double (nullable = true)\n |-- lepton_phi: double (nullable = true)\n |-- missing_energy_magnitude: double (nullable = true)\n |-- missing_energy_phi: double (nullable = true)\n |-- jet_1_pt: double (nullable = true)\n |-- jet_1_eta: double (nullable = true)\n |-- jet_1_phi: double (nullable = true)\n |-- jet_1_b_tag: double (nullable = true)\n |-- jet_2_pt: double (nullable = true)\n |-- jet_2_eta: double (nullable = true)\n |-- jet_2_phi: double (nullable = true)\n |-- jet_2_b_tag: double (nullable = true)\n |-- jet_3_pt: double (nullable = true)\n |-- jet_3_eta: double (nullable = true)\n |-- jet_3_phi: double (nullable = true)\n |-- jet_3_b_tag: double (nullable = true)\n |-- jet_4_pt: double (nullable = true)\n |-- jet_4_eta: double (nullable = true)\n |-- jet_4_phi: double (nullable = true)\n |-- jet_4_b_tag: double (nullable = true)\n |-- m_jj: double (nullable = true)\n |-- m_jjj: double (nullable = true)\n |-- m_lv: double (nullable = true)\n |-- m_jlv: double (nullable = true)\n |-- m_bb: double (nullable = true)\n |-- m_wbb: double (nullable = true)\n |-- m_wwbb: double (nullable = true)\n |-- new_column: integer (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1525285162144_-675143499","id":"20180502-131922_960230122","dateCreated":"2018-05-02T13:19:22-0500","dateStarted":"2018-05-02T13:20:10-0500","dateFinished":"2018-05-02T13:20:10-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9535"},{"text":"%md\n\n# End of Lesson 2","user":"anonymous","dateUpdated":"2018-05-02T13:35:34-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>End of Lesson 2</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525286109861_-269433744","id":"20180502-133509_1148514373","dateCreated":"2018-05-02T13:35:09-0500","dateStarted":"2018-05-02T13:35:34-0500","dateFinished":"2018-05-02T13:35:34-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9536"},{"text":"%md\n\n# Start of Lesson 3","user":"anonymous","dateUpdated":"2018-05-02T13:35:38-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Start of Lesson 3</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525286135592_-1480977382","id":"20180502-133535_1270805594","dateCreated":"2018-05-02T13:35:35-0500","dateStarted":"2018-05-02T13:35:38-0500","dateFinished":"2018-05-02T13:35:38-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9537"},{"title":"Lesson 3-1: Counting Rows","text":"%pyspark\n\ndf.count()","user":"anonymous","dateUpdated":"2018-05-02T13:36:41-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"11000000\n"}]},"apps":[],"jobName":"paragraph_1525195875820_1298254459","id":"20180501-123115_1088597781","dateCreated":"2018-05-01T12:31:15-0500","dateStarted":"2018-05-02T13:36:41-0500","dateFinished":"2018-05-02T13:36:59-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9538"},{"title":"Lesson 3-2-1: Filtering Rows w/filter","text":"%pyspark\n\ndf.filter(col(\"target\") == 1).select(\"target\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T14:01:04-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+\n|target|\n+------+\n|   1.0|\n|   1.0|\n|   1.0|\n|   1.0|\n|   1.0|\n+------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525196601850_-1606604671","id":"20180501-124321_1330910074","dateCreated":"2018-05-01T12:43:21-0500","dateStarted":"2018-05-02T14:01:04-0500","dateFinished":"2018-05-02T14:01:04-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9539"},{"title":"Lesson 3-2-2: Filtering Rows w/where","text":"%pyspark\n\ndf.where(\"target == 1\").select(\"target\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T14:00:59-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true,"editorHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+\n|target|\n+------+\n|   1.0|\n|   1.0|\n|   1.0|\n|   1.0|\n|   1.0|\n+------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525286326731_-1940323241","id":"20180502-133846_899645430","dateCreated":"2018-05-02T13:38:46-0500","dateStarted":"2018-05-02T14:00:59-0500","dateFinished":"2018-05-02T14:00:59-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9540"},{"text":"%md\n\nSpark effortlessly handles multiple filters, so there's no need to make complicated expressions. Simply chain your filters!","user":"anonymous","dateUpdated":"2018-05-02T13:40:48-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"text","editOnDblClick":false},"editorMode":"ace/mode/text","editorHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Spark effortlessly handles multiple filters, so there&rsquo;s no need to make complicated expressions. Simply chain your filters!</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525286375693_-513396840","id":"20180502-133935_480333348","dateCreated":"2018-05-02T13:39:35-0500","dateStarted":"2018-05-02T13:40:46-0500","dateFinished":"2018-05-02T13:40:46-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9541"},{"title":"Lesso 3-2-3: Multiple Filters","text":"%pyspark\n\n# return number of rows meeting filters\ndf.where(\"target == 1\").where(\"lepton_pT > 1\").where(\"lepton_eta < 2\").count()","user":"anonymous","dateUpdated":"2018-05-02T13:44:06-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2145877\n"}]},"apps":[],"jobName":"paragraph_1525196710451_2015806224","id":"20180501-124510_1034562873","dateCreated":"2018-05-01T12:45:10-0500","dateStarted":"2018-05-02T13:43:19-0500","dateFinished":"2018-05-02T13:43:42-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9542"},{"title":"Lesson 3-3: Return Unique Rows","text":"%pyspark\n\n# return number of classes\ndf.select(\"target\").distinct().count()","user":"anonymous","dateUpdated":"2018-05-02T13:45:56-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2\n"}]},"apps":[],"jobName":"paragraph_1525286578630_-1649870114","id":"20180502-134258_1401641988","dateCreated":"2018-05-02T13:42:58-0500","dateStarted":"2018-05-02T13:45:16-0500","dateFinished":"2018-05-02T13:45:36-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9543"},{"title":"Lesson 3-4: Random Samples","text":"%pyspark\n\nwithReplacement = False\nfraction = 0.001\nseed = 42\n\ndf.sample(withReplacement, fraction, seed).count()","user":"anonymous","dateUpdated":"2018-05-02T13:48:17-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"10946\n"}]},"apps":[],"jobName":"paragraph_1525286716423_1517180328","id":"20180502-134516_1579251914","dateCreated":"2018-05-02T13:45:16-0500","dateStarted":"2018-05-02T13:48:17-0500","dateFinished":"2018-05-02T13:48:36-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9544"},{"title":"Lesson 3-5: Randomly Split DF","text":"%pyspark\n\ndataframes = df.randomSplit([0.75, 0.25], seed)\nprint(\"1st DF:\", dataframes[0].count(), \"\\n2nd DF:\", dataframes[1].count())","user":"anonymous","dateUpdated":"2018-05-02T13:53:41-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1st DF: 8252681 \n2nd DF: 2747319\n"}]},"apps":[],"jobName":"paragraph_1525286826632_-91885545","id":"20180502-134706_355635204","dateCreated":"2018-05-02T13:47:06-0500","dateStarted":"2018-05-02T13:53:41-0500","dateFinished":"2018-05-02T13:56:16-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9545"},{"title":"Lesson 3-6: Sort Rows (ascending = default)","text":"%pyspark\n\ndf.sort(\"lepton_pT\").select(\"lepton_pT\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T14:00:19-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------------+\n|         lepton_pT|\n+------------------+\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525287047455_381474383","id":"20180502-135047_728217396","dateCreated":"2018-05-02T13:50:47-0500","dateStarted":"2018-05-02T14:00:19-0500","dateFinished":"2018-05-02T14:00:42-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9546"},{"title":"Same as above but different method","text":"%pyspark\n\ndf.orderBy(\"lepton_pT\").select(\"lepton_pT\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T14:03:16-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------------+\n|         lepton_pT|\n+------------------+\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525287730912_-1340864197","id":"20180502-140210_2097562855","dateCreated":"2018-05-02T14:02:10-0500","dateStarted":"2018-05-02T14:03:16-0500","dateFinished":"2018-05-02T14:03:39-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9547"},{"title":"Lesson 3-6: Sort Rows (select direction)","text":"%pyspark\n\nfrom pyspark.sql.functions import asc, desc\n\ndf.orderBy(expr(\"lepton_pT desc\")).select(\"lepton_pT\").show(5)","user":"anonymous","dateUpdated":"2018-05-02T14:04:53-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------------------+\n|         lepton_pT|\n+------------------+\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n|0.2746966481208801|\n+------------------+\nonly showing top 5 rows\n\n"}]},"apps":[],"jobName":"paragraph_1525287440546_1428560030","id":"20180502-135720_2117467778","dateCreated":"2018-05-02T13:57:20-0500","dateStarted":"2018-05-02T14:04:53-0500","dateFinished":"2018-05-02T14:05:17-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9548"},{"text":"%md\n\nUse **asc_nulls_first**, **desc_nulls_first**, **asc_nulls_last**, or **desc_nulls_last** to control how null values are sorted.\n\nYou can also sort within each partition prior to performing some transformation. Sometimes this makes sense as it will optimize performance. THe details are outside the scope of this tutorial but check **sortWithinPartition** in the docs for details.","user":"anonymous","dateUpdated":"2018-05-02T14:07:46-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Use <strong>asc_nulls_first</strong>, <strong>desc_nulls_first</strong>, <strong>asc_nulls_last</strong>, or <strong>desc_nulls_last</strong> to control how null values are sorted.</p>\n<p>You can also sort within each partition prior to performing some transformation. Sometimes this makes sense as it will optimize performance. THe details are outside the scope of this tutorial but check <strong>sortWithinPartition</strong> in the docs for details.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525287912926_-1763258837","id":"20180502-140512_652371214","dateCreated":"2018-05-02T14:05:12-0500","dateStarted":"2018-05-02T14:07:46-0500","dateFinished":"2018-05-02T14:07:46-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9549"},{"title":"Lesson 3-7: Limit","text":"%pyspark\n\ndf.select(\"target\", \"lepton_pT\").limit(5).show()","user":"anonymous","dateUpdated":"2018-05-02T14:09:22-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+------------------+\n|target|         lepton_pT|\n+------+------------------+\n|   1.0|0.7675400972366333|\n|   1.0|0.5195627808570862|\n|   1.0|1.0063670873641968|\n|   1.0|1.4637067317962646|\n|   0.0|1.7219325304031372|\n+------+------------------+\n\n"}]},"apps":[],"jobName":"paragraph_1525287893649_1592875170","id":"20180502-140453_163372764","dateCreated":"2018-05-02T14:04:53-0500","dateStarted":"2018-05-02T14:09:22-0500","dateFinished":"2018-05-02T14:09:22-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9550"},{"text":"%md\n\n# End of Lesson 3","user":"anonymous","dateUpdated":"2018-05-02T14:11:28-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>End of Lesson 3</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525288280257_1226147051","id":"20180502-141120_1093156069","dateCreated":"2018-05-02T14:11:20-0500","dateStarted":"2018-05-02T14:11:28-0500","dateFinished":"2018-05-02T14:11:28-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9551"},{"text":"%md\n\n# Start of Lesson 4","user":"anonymous","dateUpdated":"2018-05-02T14:11:39-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Start of Lesson 4</h1>\n</div>"}]},"apps":[],"jobName":"paragraph_1525288291110_-1273566553","id":"20180502-141131_1557173461","dateCreated":"2018-05-02T14:11:31-0500","dateStarted":"2018-05-02T14:11:39-0500","dateFinished":"2018-05-02T14:11:39-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9552"},{"title":"Lesson 4: Overview","text":"%md\n\nSometimes it makes sense to repartition data according to some frequently filtered columns. This can lead to dramatic performance gains. \n\nDo note that repartitioning incurs a full shuffle of the data, even if one is not necessary. \n\nTherefore, only repartition when you are looking to create more partitions, not less. \n\nOn the othere hand, coalesce will try to combine partitions. Importantly, it will not incur a full shuffle.","user":"anonymous","dateUpdated":"2018-05-02T14:14:32-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false,"title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Sometimes it makes sense to repartition data according to some frequently filtered columns. This can lead to dramatic performance gains. </p>\n<p>Do note that repartitioning incurs a full shuffle of the data, even if one is not necessary. </p>\n<p>Therefore, only repartition when you are looking to create more partitions, not less. </p>\n<p>On the othere hand, coalesce will try to combine partitions. Importantly, it will not incur a full shuffle.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1525288302050_486674989","id":"20180502-141142_1879161151","dateCreated":"2018-05-02T14:11:42-0500","dateStarted":"2018-05-02T14:14:18-0500","dateFinished":"2018-05-02T14:14:18-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9553"},{"title":"Lesson 4-1: Number of Partitions","text":"%pyspark\n\ndf.rdd.getNumPartitions()","user":"anonymous","dateUpdated":"2018-05-02T14:15:26-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"60\n"}]},"apps":[],"jobName":"paragraph_1525288175067_1034421149","id":"20180502-140935_144960687","dateCreated":"2018-05-02T14:09:35-0500","dateStarted":"2018-05-02T14:14:55-0500","dateFinished":"2018-05-02T14:14:55-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9554"},{"title":"Lesson 4-2: Coalesce --> 10 Partitions","text":"%pyspark\n\ndf = df.coalesce(10)\ndf.rdd.getNumPartitions()","user":"anonymous","dateUpdated":"2018-05-02T14:16:35-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"10\n"}]},"apps":[],"jobName":"paragraph_1525288490694_1689124215","id":"20180502-141450_2089604103","dateCreated":"2018-05-02T14:14:50-0500","dateStarted":"2018-05-02T14:16:35-0500","dateFinished":"2018-05-02T14:16:35-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9555"},{"title":"Lesson 4-3: Repartition --> 25 Partitions","text":"%pyspark\n\ndf = df.repartition(25)\ndf.rdd.getNumPartitions()","user":"anonymous","dateUpdated":"2018-05-02T14:17:23-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python","title":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"25\n"}]},"apps":[],"jobName":"paragraph_1525288575399_-461732694","id":"20180502-141615_1889353017","dateCreated":"2018-05-02T14:16:15-0500","dateStarted":"2018-05-02T14:17:23-0500","dateFinished":"2018-05-02T14:17:23-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:9556"},{"text":"%pyspark\n","user":"anonymous","dateUpdated":"2018-05-02T14:18:23-0500","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1525288703651_-1826636257","id":"20180502-141823_817921042","dateCreated":"2018-05-02T14:18:23-0500","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:9557"}],"name":"03_Spark_Fundamental_Structured_Operations","id":"2DDE3JKWW","angularObjects":{"2CZWR1GGK:shared_process":[],"2CZ7856YP:shared_process":[],"2CX8JPHEF:shared_process":[],"2D186B2WU:shared_process":[],"2CY5HAT7D:shared_process":[],"2CZB79PJH:shared_process":[],"2CYFPK9UY:shared_process":[],"2CZPQ5RPQ:shared_process":[],"2CYH9N1YV:shared_process":[],"2CYCTCHVJ:shared_process":[],"2CXPH91QU:shared_process":[],"2CY7DV8BJ:shared_process":[],"2CZ846CKC:shared_process":[],"2CZ5JZ2DK:shared_process":[],"2CZ9C6XMZ:shared_process":[],"2D1TA5NMG:shared_process":[],"2CYEN6EZN:shared_process":[],"2CXA6C49M:shared_process":[],"2CY7EH4R3:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}