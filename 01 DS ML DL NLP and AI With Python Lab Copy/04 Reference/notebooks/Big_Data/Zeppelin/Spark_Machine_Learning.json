{"paragraphs":[{"title":"Introduction","text":"%md\nThis notebook is a simple tutorial on how to use numpy, pandas, and Spark's machine learning library to do fun stuff.","dateUpdated":"2017-11-16T10:51:29-0500","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1510851089289_1997836653","id":"20171109-133205_1077344504","dateCreated":"2017-11-16T10:51:29-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8324"},{"title":"Imports","text":"%pyspark\n\nimport pandas as pd","user":"anonymous","dateUpdated":"2018-04-19T16:41:47-0400","config":{"editorSetting":{"language":"python","editOnDblClick":false},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089290_1998990900","id":"20171109-132043_872043916","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:41:47-0400","dateFinished":"2018-04-19T16:41:47-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8325"},{"text":"%pyspark\n\npath = \"/Users/davidziganto/data/\"\n\ncolumns = ['target', 'cluster_id', 'game_mode', 'game_type', \"antimage\", \"axe\", \"bane\", \"bloodseeker\", \"crystal_maiden\", \"drow_ranger\", \"earthshaker\", \"juggernaut\", \"mirana\", \"nevermore\", \"morphling\", \"phantom_lancer\", \"puck\", \"pudge\", \"razor\", \"sand_king\", \"storm_spirit\", \"sven\", \"tiny\", \"vengefulspirit\", \"windrunner\", \"zuus\", \"kunkka\", \"lina\", \"lich\", \"lion\", \"shadow_shaman\", \"slardar\", \"tidehunter\", \"witch_doctor\", \"riki\", \"enigma\", \"tinker\", \"sniper\", \"necrolyte\", \"warlock\", \"beastmaster\", \"queenofpain\", \"venomancer\", \"faceless_void\", \"skeleton_king\", \"death_prophet\", \"phantom_assassin\", \"pugna\", \"templar_assassin\", \"viper\", \"luna\", \"dragon_knight\", \"dazzle\", \"rattletrap\", \"leshrac\", \"furion\", \"life_stealer\", \"dark_seer\", \"clinkz\", \"omniknight\", \"enchantress\", \"huskar\", \"night_stalker\", \"broodmother\", \"bounty_hunter\", \"weaver\", \"jakiro\", \"batrider\", \"chen\", \"spectre\", \"doom_bringer\", \"ancient_apparition\", \"ursa\", \"spirit_breaker\", \"gyrocopter\", \"alchemist\", \"invoker\", \"silencer\", \"obsidian_destroyer\", \"lycan\", \"brewmaster\", \"shadow_demon\", \"lone_druid\", \"chaos_knight\", \"meepo\", \"treant\", \"ogre_magi\", \"undying\", \"rubick\", \"disruptor\", \"nyx_assassin\", \"naga_siren\", \"keeper_of_the_light\", \"wisp\", \"visage\", \"slark\", \"medusa\", \"troll_warlord\", \"centaur\", \"magnataur\", \"shredder\", \"bristleback\", \"tusk\", \"skywrath_mage\", \"abaddon\", \"elder_titan\", \"legion_commander\", \"ember_spirit\", \"earth_spirit\", \"abyssal_underlord\", \"terrorblade\", \"phoenix\", \"techies\", \"oracle\", \"winter_wyvern\", \"arc_warden\", \"other\"]\n\n# get train data\nX_train = pd.read_csv(path + 'dota2Train.csv', names=columns)\nX_train.target.replace(-1, 0, inplace=True)\n\n# get test data\nX_test = pd.read_csv(path + 'dota2Test.csv', names=columns)\nX_test.target.replace(-1, 0, inplace=True)","user":"anonymous","dateUpdated":"2018-04-19T16:42:54-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089290_1998990900","id":"20171109-132057_845151643","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:42:54-0400","dateFinished":"2018-04-19T16:42:56-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8326"},{"text":"%pyspark\n\ntrain_data = spark.createDataFrame(X_train)\ntest_data = spark.createDataFrame(X_test)","user":"anonymous","dateUpdated":"2018-04-19T16:43:08-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1524170419019_1226883347","id":"20180419-164019_581999294","dateCreated":"2018-04-19T16:40:19-0400","dateStarted":"2018-04-19T16:43:08-0400","dateFinished":"2018-04-19T16:45:49-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8327"},{"title":"Rearrange Rows","text":"%pyspark\n\ntype(train_data)","user":"anonymous","dateUpdated":"2018-04-19T16:43:19-0400","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"<class 'pyspark.sql.dataframe.DataFrame'>\n"}]},"apps":[],"jobName":"paragraph_1510851089290_1998990900","id":"20171109-145022_1858055191","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:43:19-0400","dateFinished":"2018-04-19T16:45:49-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8328"},{"text":"%pyspark\n\ntrain_data.printSchema()","user":"anonymous","dateUpdated":"2018-04-19T16:43:29-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"root\n |-- target: long (nullable = true)\n |-- cluster_id: long (nullable = true)\n |-- game_mode: long (nullable = true)\n |-- game_type: long (nullable = true)\n |-- antimage: long (nullable = true)\n |-- axe: long (nullable = true)\n |-- bane: long (nullable = true)\n |-- bloodseeker: long (nullable = true)\n |-- crystal_maiden: long (nullable = true)\n |-- drow_ranger: long (nullable = true)\n |-- earthshaker: long (nullable = true)\n |-- juggernaut: long (nullable = true)\n |-- mirana: long (nullable = true)\n |-- nevermore: long (nullable = true)\n |-- morphling: long (nullable = true)\n |-- phantom_lancer: long (nullable = true)\n |-- puck: long (nullable = true)\n |-- pudge: long (nullable = true)\n |-- razor: long (nullable = true)\n |-- sand_king: long (nullable = true)\n |-- storm_spirit: long (nullable = true)\n |-- sven: long (nullable = true)\n |-- tiny: long (nullable = true)\n |-- vengefulspirit: long (nullable = true)\n |-- windrunner: long (nullable = true)\n |-- zuus: long (nullable = true)\n |-- kunkka: long (nullable = true)\n |-- lina: long (nullable = true)\n |-- lich: long (nullable = true)\n |-- lion: long (nullable = true)\n |-- shadow_shaman: long (nullable = true)\n |-- slardar: long (nullable = true)\n |-- tidehunter: long (nullable = true)\n |-- witch_doctor: long (nullable = true)\n |-- riki: long (nullable = true)\n |-- enigma: long (nullable = true)\n |-- tinker: long (nullable = true)\n |-- sniper: long (nullable = true)\n |-- necrolyte: long (nullable = true)\n |-- warlock: long (nullable = true)\n |-- beastmaster: long (nullable = true)\n |-- queenofpain: long (nullable = true)\n |-- venomancer: long (nullable = true)\n |-- faceless_void: long (nullable = true)\n |-- skeleton_king: long (nullable = true)\n |-- death_prophet: long (nullable = true)\n |-- phantom_assassin: long (nullable = true)\n |-- pugna: long (nullable = true)\n |-- templar_assassin: long (nullable = true)\n |-- viper: long (nullable = true)\n |-- luna: long (nullable = true)\n |-- dragon_knight: long (nullable = true)\n |-- dazzle: long (nullable = true)\n |-- rattletrap: long (nullable = true)\n |-- leshrac: long (nullable = true)\n |-- furion: long (nullable = true)\n |-- life_stealer: long (nullable = true)\n |-- dark_seer: long (nullable = true)\n |-- clinkz: long (nullable = true)\n |-- omniknight: long (nullable = true)\n |-- enchantress: long (nullable = true)\n |-- huskar: long (nullable = true)\n |-- night_stalker: long (nullable = true)\n |-- broodmother: long (nullable = true)\n |-- bounty_hunter: long (nullable = true)\n |-- weaver: long (nullable = true)\n |-- jakiro: long (nullable = true)\n |-- batrider: long (nullable = true)\n |-- chen: long (nullable = true)\n |-- spectre: long (nullable = true)\n |-- doom_bringer: long (nullable = true)\n |-- ancient_apparition: long (nullable = true)\n |-- ursa: long (nullable = true)\n |-- spirit_breaker: long (nullable = true)\n |-- gyrocopter: long (nullable = true)\n |-- alchemist: long (nullable = true)\n |-- invoker: long (nullable = true)\n |-- silencer: long (nullable = true)\n |-- obsidian_destroyer: long (nullable = true)\n |-- lycan: long (nullable = true)\n |-- brewmaster: long (nullable = true)\n |-- shadow_demon: long (nullable = true)\n |-- lone_druid: long (nullable = true)\n |-- chaos_knight: long (nullable = true)\n |-- meepo: long (nullable = true)\n |-- treant: long (nullable = true)\n |-- ogre_magi: long (nullable = true)\n |-- undying: long (nullable = true)\n |-- rubick: long (nullable = true)\n |-- disruptor: long (nullable = true)\n |-- nyx_assassin: long (nullable = true)\n |-- naga_siren: long (nullable = true)\n |-- keeper_of_the_light: long (nullable = true)\n |-- wisp: long (nullable = true)\n |-- visage: long (nullable = true)\n |-- slark: long (nullable = true)\n |-- medusa: long (nullable = true)\n |-- troll_warlord: long (nullable = true)\n |-- centaur: long (nullable = true)\n |-- magnataur: long (nullable = true)\n |-- shredder: long (nullable = true)\n |-- bristleback: long (nullable = true)\n |-- tusk: long (nullable = true)\n |-- skywrath_mage: long (nullable = true)\n |-- abaddon: long (nullable = true)\n |-- elder_titan: long (nullable = true)\n |-- legion_commander: long (nullable = true)\n |-- ember_spirit: long (nullable = true)\n |-- earth_spirit: long (nullable = true)\n |-- abyssal_underlord: long (nullable = true)\n |-- terrorblade: long (nullable = true)\n |-- phoenix: long (nullable = true)\n |-- techies: long (nullable = true)\n |-- oracle: long (nullable = true)\n |-- winter_wyvern: long (nullable = true)\n |-- arc_warden: long (nullable = true)\n |-- other: long (nullable = true)\n\n"}]},"apps":[],"jobName":"paragraph_1510851089290_1998990900","id":"20171109-140810_1298767575","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:45:49-0400","dateFinished":"2018-04-19T16:45:49-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8329"},{"title":"Create Spark DF","text":"%pyspark\n\ntrain_data.take(1)","user":"anonymous","dateUpdated":"2018-04-19T16:43:38-0400","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[Row(target=0, cluster_id=223, game_mode=2, game_type=2, antimage=0, axe=0, bane=0, bloodseeker=0, crystal_maiden=0, drow_ranger=0, earthshaker=0, juggernaut=0, mirana=0, nevermore=1, morphling=0, phantom_lancer=0, puck=0, pudge=1, razor=0, sand_king=0, storm_spirit=0, sven=-1, tiny=0, vengefulspirit=0, windrunner=0, zuus=-1, kunkka=0, lina=0, lich=1, lion=0, shadow_shaman=0, slardar=1, tidehunter=0, witch_doctor=0, riki=0, enigma=1, tinker=0, sniper=0, necrolyte=0, warlock=0, beastmaster=0, queenofpain=-1, venomancer=0, faceless_void=0, skeleton_king=0, death_prophet=0, phantom_assassin=0, pugna=0, templar_assassin=0, viper=0, luna=0, dragon_knight=0, dazzle=0, rattletrap=0, leshrac=0, furion=0, life_stealer=0, dark_seer=0, clinkz=0, omniknight=0, enchantress=0, huskar=0, night_stalker=0, broodmother=0, bounty_hunter=0, weaver=0, jakiro=0, batrider=0, chen=0, spectre=0, doom_bringer=0, ancient_apparition=0, ursa=0, spirit_breaker=0, gyrocopter=0, alchemist=0, invoker=0, silencer=-1, obsidian_destroyer=0, lycan=0, brewmaster=0, shadow_demon=0, lone_druid=0, chaos_knight=0, meepo=0, treant=0, ogre_magi=0, undying=0, rubick=0, disruptor=0, nyx_assassin=0, naga_siren=-1, keeper_of_the_light=0, wisp=0, visage=0, slark=0, medusa=0, troll_warlord=0, centaur=0, magnataur=0, shredder=0, bristleback=0, tusk=0, skywrath_mage=0, abaddon=0, elder_titan=0, legion_commander=0, ember_spirit=0, earth_spirit=0, abyssal_underlord=0, terrorblade=0, phoenix=0, techies=0, oracle=0, winter_wyvern=0, arc_warden=0, other=0)]\n"}]},"apps":[],"jobName":"paragraph_1510851089291_1998606151","id":"20171109-132121_1872338822","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:45:49-0400","dateFinished":"2018-04-19T16:45:51-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8330"},{"text":"%pyspark\n\n# Spark SQL allows us to explore data using SQL syntax. Let's examing the breakdown of churned customers. To perform SQL queries, the tables have to be registered using the registerTempTable method.\n\ntrain_data.registerTempTable('train_data')\n\ntarget_counts = spark.sql(r\"\"\"SELECT target, COUNT(target) AS total\n                              FROM train_data\n                              GROUP BY target\"\"\")\n                              \ntarget_counts.show()","user":"anonymous","dateUpdated":"2018-04-19T16:43:47-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+------+-----+\n|target|total|\n+------+-----+\n|     0|43868|\n|     1|48782|\n+------+-----+\n\n"}]},"apps":[],"jobName":"paragraph_1510851089292_1996682406","id":"20171109-140754_1396222594","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:45:49-0400","dateFinished":"2018-04-19T16:45:55-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8331"},{"text":"%pyspark\n\nfrom pyspark.ml.feature import VectorAssembler\n\n# the feature columns\nfeatures = train_data.schema.names[1:]\n\n# assembler object\nassembler = VectorAssembler(inputCols=features, outputCol='features')\n\n# transform train and test data\ntrain_pack = assembler.transform(train_data)\ntest_pack = assembler.transform(test_data)","user":"anonymous","dateUpdated":"2018-04-19T16:47:05-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1524170821631_-2133178059","id":"20180419-164701_1532529823","dateCreated":"2018-04-19T16:47:01-0400","dateStarted":"2018-04-19T16:47:05-0400","dateFinished":"2018-04-19T16:47:06-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8332"},{"title":"Number of Rows","text":"%md\n\nNow we get to the fun part–machine learning!\n\nPySpark has two machine learning libraries:\n\n**MLlib:** older, based on RDDs, more complete, but no additional features are being added as of Spark 2.0\n**ML:** the future, based on DataFrames, less feature complete than MLlib but this is improving\n\nOften the name MLlib is used to refer to both libraries, so context is important and this can be confusing. We will be using ML whenever possible.","user":"anonymous","dateUpdated":"2018-04-19T16:45:04-0400","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","title":true,"results":{},"enabled":true,"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now we get to the fun part–machine learning!</p>\n<p>PySpark has two machine learning libraries:</p>\n<p><strong>MLlib:</strong> older, based on RDDs, more complete, but no additional features are being added as of Spark 2.0<br/><strong>ML:</strong> the future, based on DataFrames, less feature complete than MLlib but this is improving</p>\n<p>Often the name MLlib is used to refer to both libraries, so context is important and this can be confusing. We will be using ML whenever possible.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510851089292_1996682406","id":"20171109-143053_1622356792","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:45:04-0400","dateFinished":"2018-04-19T16:45:04-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8333"},{"title":"Quick Peek","text":"%pyspark\n\nfrom pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier, GBTClassifier, LogisticRegression\n\n# logistic regression\nlr = LogisticRegression(labelCol='target', \n                        featuresCol='features',\n                        predictionCol='prediction')\n\nlr_model = lr.fit(train_pack)\nlr_pred = lr_model.transform(test_pack)\n\n# Decision Tree (depth = 2)\ndt = DecisionTreeClassifier(maxDepth=3, \n                            labelCol='target', \n                            featuresCol='features',\n                            predictionCol='prediction')\n\ndt_model = dt.fit(train_pack)\ndt_pred = dt_model.transform(test_pack)\n\n# Random Forest (also of depth = 4)\nrf = RandomForestClassifier(maxDepth=4, \n                            labelCol='target',\n                            featuresCol='features',\n                            predictionCol='prediction')\n\nrf_model = rf.fit(train_pack)\nrf_pred = rf_model.transform(test_pack)\n\n# Gradient Boosted Tree (depth = 1)\ngbt = GBTClassifier(maxDepth=1, \n                    labelCol='target', \n                    featuresCol='features',\n                    predictionCol='prediction')\n\ngbt_model = gbt.fit(train_pack)\ngbt_pred = gbt_model.transform(test_pack)","user":"anonymous","dateUpdated":"2018-04-19T16:47:08-0400","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089292_1996682406","id":"20171109-132809_629688564","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:47:08-0400","dateFinished":"2018-04-19T16:48:02-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8334"},{"title":"","text":"%md\n\n# Model Evaluation\n\nPySpark also has error metrics that are similar to those found in Scikit-learn. They are divided into metrics appropriate only for binary classifications (ROC and Precision-Recall curve related metrics) and those that also apply to multi-class classifications","user":"anonymous","dateUpdated":"2018-04-19T16:46:05-0400","config":{"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","title":true,"results":{},"enabled":true,"editorHide":false,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h1>Model Evaluation</h1>\n<p>PySpark also has error metrics that are similar to those found in Scikit-learn. They are divided into metrics appropriate only for binary classifications (ROC and Precision-Recall curve related metrics) and those that also apply to multi-class classifications</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510851089292_1996682406","id":"20171109-132743_239942099","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:46:01-0400","dateFinished":"2018-04-19T16:46:01-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8335"},{"title":"Better Format","text":"%pyspark\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n\naccuracy = MulticlassClassificationEvaluator(labelCol='target', \n                                             predictionCol='prediction',\n                                             metricName='accuracy')\n\nprecision = MulticlassClassificationEvaluator(labelCol='target', \n                                              predictionCol='prediction',\n                                              metricName='weightedPrecision')\n\nrecall = MulticlassClassificationEvaluator(labelCol='target', \n                                           predictionCol='prediction',\n                                           metricName='weightedRecall')\n\nf1 = MulticlassClassificationEvaluator(labelCol='target', \n                                       predictionCol='prediction',\n                                       metricName='f1')\n\nareaROC = BinaryClassificationEvaluator(labelCol='target',\n                                        rawPredictionCol='prediction',\n                                        metricName='areaUnderROC')\n\nareaPR = BinaryClassificationEvaluator(labelCol='target',\n                                       rawPredictionCol='prediction',\n                                       metricName='areaUnderPR')\n","user":"anonymous","dateUpdated":"2018-04-19T16:47:32-0400","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","title":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089292_1996682406","id":"20171109-141522_1465708413","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:47:32-0400","dateFinished":"2018-04-19T16:48:02-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8336"},{"text":"%md\n\nThese metrics can be used to create a table of the values for each model's predictions.","user":"anonymous","dateUpdated":"2018-04-19T16:47:51-0400","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>These metrics can be used to create a table of the values for each model&rsquo;s predictions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510851089292_1996682406","id":"20171109-141735_398438825","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:47:51-0400","dateFinished":"2018-04-19T16:47:51-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8337"},{"text":"%pyspark\n\n# the error metrics\nmetrics = [accuracy, precision, recall, f1, areaROC, areaPR]\nmetric_labels = ['accuracy', 'precision', 'recall', 'f1', 'areaROC', 'areaPR']\n\n# the predictions from each model\npredictions = [lr_pred, dt_pred, rf_pred, gbt_pred]\npredict_labels = ['LR', 'DT', 'RF', 'GBT']\n\neval_list = list()\n\n# for each model's predictions, calculate error metrics\n# and add to a Pandas series\nfor pred in zip(predict_labels, predictions):\n    name = pred[0]\n    predict = pred[1]\n    \n    metric_vals = pd.Series(dict([(x[0], x[1].evaluate(predict)) \n                                 for x in zip(metric_labels, metrics)]),\n                            name=name)\n    eval_list.append(metric_vals)\n    \n# combine all the series into a dataframe\neval_df = pd.concat(eval_list, axis=1).T\neval_df = eval_df[metric_labels]\neval_df","user":"anonymous","dateUpdated":"2018-04-19T16:48:08-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"     accuracy  precision    recall        f1   areaROC    areaPR\nLR   0.597824   0.596010  0.597824  0.595522  0.592562  0.729691\nDT   0.539149   0.542859  0.539149  0.417194  0.508078  0.759711\nRF   0.547989   0.599115  0.547989  0.423016  0.516429  0.765457\nGBT  0.556926   0.561728  0.556926  0.497964  0.533636  0.747255\n"}]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-142050_1844692829","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:48:08-0400","dateFinished":"2018-04-19T16:48:22-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8338"},{"text":"%pyspark\n\n# the predictions from each model\npredictions = [lr_pred, dt_pred, rf_pred, gbt_pred]\npredict_labels = ['LR', 'DT', 'RF', 'GBT']","user":"anonymous","dateUpdated":"2018-04-19T16:48:18-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-143059_355393844","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:48:18-0400","dateFinished":"2018-04-19T16:48:22-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8339"},{"text":"%md\n\nAny feature transformations and model fitting can be combined into a pipeline. Pipelines are useful because:\n\n1. The data can be split before any transformations that may lead to leakage of the test data.\n2. Simultaneously ensure that the split data sets are treated identically.\n3. We don't do much in this example for feature transformation other than assembling all the features into one column and scaling, but let's use that to create a pipeline for the logistic regression model we used above.\n\nIf we did do extensive feature engineering, then having a pipeline would be extremely beneificial. (Just like in scikit-learn.)","user":"anonymous","dateUpdated":"2018-04-19T16:48:46-0400","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Any feature transformations and model fitting can be combined into a pipeline. Pipelines are useful because:</p>\n<ol>\n  <li>The data can be split before any transformations that may lead to leakage of the test data.</li>\n  <li>Simultaneously ensure that the split data sets are treated identically.</li>\n  <li>We don&rsquo;t do much in this example for feature transformation other than assembling all the features into one column and scaling, but let&rsquo;s use that to create a pipeline for the logistic regression model we used above.</li>\n</ol>\n<p>If we did do extensive feature engineering, then having a pipeline would be extremely beneificial. (Just like in scikit-learn.)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-143358_1110597847","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:48:46-0400","dateFinished":"2018-04-19T16:48:46-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8340"},{"text":"%pyspark\n\nfrom pyspark.ml import Pipeline\n\n# the pipline\npipeline = Pipeline(stages=[assembler, lr]) \n\n# fit and transform\nlr_model2 = pipeline.fit(train_data)\nlr_pred2 = lr_model2.transform(test_data)","user":"anonymous","dateUpdated":"2018-04-19T16:49:01-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-152426_2092064614","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:49:01-0400","dateFinished":"2018-04-19T16:49:05-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8341"},{"text":"%pyspark\n\n# GRID SEARCH & CV\n\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# the GradientBoostedTree model\ngbt2 = GBTClassifier(featuresCol='features',\n                     labelCol='target', \n                     predictionCol='prediction')\n \n# the pipline\npipeline = Pipeline(stages=[assembler, gbt2]) \n\n# the parameter grid--we'll optimize maxDepth and stepSize\nparamgrid = (ParamGridBuilder().addGrid(gbt2.maxDepth, [2, 3])\n                               .addGrid(gbt2.stepSize, [0.01, 0.1, 1.0]).build())\n\n# use f1 score as the evaluation metric for best model \nevaluator = MulticlassClassificationEvaluator(labelCol='target', \n                                              predictionCol='prediction', \n                                              metricName='f1') \n\n# use 3-fold cross validation \ncrossval = CrossValidator(estimator=pipeline, \n                          estimatorParamMaps=paramgrid, \n                          evaluator=evaluator, \n                          numFolds=3) \n\ngbt2_model = crossval.fit(train_data)","user":"anonymous","dateUpdated":"2018-04-19T16:49:11-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-145856_1022628746","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:49:11-0400","dateFinished":"2018-04-19T16:58:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8342"},{"text":"%md\n\nMuch like with Scikit-learn's gridsearch function, we can probe for the best model and view its attributes.\n\nFirst, we have to select the best model, though.","user":"anonymous","dateUpdated":"2018-04-19T16:49:29-0400","config":{"colWidth":12,"editorMode":"ace/mode/markdown","results":{},"enabled":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Much like with Scikit-learn&rsquo;s gridsearch function, we can probe for the best model and view its attributes.</p>\n<p>First, we have to select the best model, though.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-152438_1562383421","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:49:29-0400","dateFinished":"2018-04-19T16:49:29-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8343"},{"text":"%pyspark\n\n# return the best pipeline based on f1 score\nbest_pipeline = gbt2_model.bestModel\n\n# return the best GBT model, which is the second step of the pipeline\nbest_gbt_model = best_pipeline.stages[1]","user":"anonymous","dateUpdated":"2018-04-19T16:49:38-0400","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"}},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[]},"apps":[],"jobName":"paragraph_1510851089293_1996297657","id":"20171109-153322_151101125","dateCreated":"2017-11-16T10:51:29-0500","dateStarted":"2018-04-19T16:49:38-0400","dateFinished":"2018-04-19T16:58:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8344"},{"text":"%md\n\nUnfortunately, not all model parameters can be extracted with PySpark, but we can extract the individual trees for GradientBoostedTrees and then examine them.","user":"anonymous","dateUpdated":"2018-04-19T16:49:58-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Unfortunately, not all model parameters can be extracted with PySpark, but we can extract the individual trees for GradientBoostedTrees and then examine them.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1524170183811_1319299181","id":"20180419-163623_111653543","dateCreated":"2018-04-19T16:36:23-0400","dateStarted":"2018-04-19T16:49:58-0400","dateFinished":"2018-04-19T16:49:58-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8345"},{"text":"%pyspark\n\n# how many trees were there?\nlen(best_gbt_model.trees)","user":"anonymous","dateUpdated":"2018-04-19T16:58:27-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"20\n"}]},"apps":[],"jobName":"paragraph_1524170993165_-1940156704","id":"20180419-164953_723200874","dateCreated":"2018-04-19T16:49:53-0400","dateStarted":"2018-04-19T16:58:27-0400","dateFinished":"2018-04-19T16:58:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8346"},{"text":"%pyspark\n\n# list some of the trees\nfor i in range(5):\n    print(best_gbt_model.trees[i])","user":"anonymous","dateUpdated":"2018-04-19T16:50:16-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DecisionTreeRegressionModel (uid=dtr_c911e89d1325) of depth 3 with 15 nodes\nDecisionTreeRegressionModel (uid=dtr_271e9773a262) of depth 3 with 15 nodes\nDecisionTreeRegressionModel (uid=dtr_e465a47fe149) of depth 3 with 15 nodes\nDecisionTreeRegressionModel (uid=dtr_48e540baa26d) of depth 3 with 15 nodes\nDecisionTreeRegressionModel (uid=dtr_a10839db9bd1) of depth 3 with 15 nodes\n"}]},"apps":[],"jobName":"paragraph_1524171008053_933948228","id":"20180419-165008_2085751955","dateCreated":"2018-04-19T16:50:08-0400","dateStarted":"2018-04-19T16:58:27-0400","dateFinished":"2018-04-19T16:58:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8347"},{"text":"%pyspark\n\n# what was the best depth?\n[x.depth for x in best_gbt_model.trees]","user":"anonymous","dateUpdated":"2018-04-19T16:50:25-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n"}]},"apps":[],"jobName":"paragraph_1524171016479_1219983582","id":"20180419-165016_131897570","dateCreated":"2018-04-19T16:50:16-0400","dateStarted":"2018-04-19T16:58:27-0400","dateFinished":"2018-04-19T16:58:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8348"},{"text":"%pyspark\n\n# extract feature importances\nfeature_importances = best_gbt_model.featureImportances.toArray()\n\n# extract feature names, except for the predictor\nfeature_names = train_data.columns[1:]\n\nfeature_series = (pd.Series(dict(zip(feature_names, feature_importances)))\n                  .sort_values(ascending=False))\n\nfeature_series","user":"anonymous","dateUpdated":"2018-04-19T16:50:33-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"life_stealer          0.077647\nabyssal_underlord     0.063384\nwindrunner            0.055097\ndeath_prophet         0.053775\nmirana                0.050101\nlegion_commander      0.041678\ndrow_ranger           0.041160\ncrystal_maiden        0.031475\nvisage                0.030890\nvenomancer            0.029171\nhuskar                0.028078\ndragon_knight         0.026064\nundying               0.025233\nenchantress           0.024438\nchaos_knight          0.024430\nsven                  0.022289\npudge                 0.022160\nenigma                0.020147\nsilencer              0.019468\ndoom_bringer          0.017547\nbounty_hunter         0.016814\nzuus                  0.016256\nobsidian_destroyer    0.015708\nlich                  0.014769\npuck                  0.013433\ntiny                  0.013367\nwinter_wyvern         0.013041\nwarlock               0.012677\nspirit_breaker        0.012588\nviper                 0.012132\n                        ...   \nrattletrap            0.000000\nrazor                 0.000000\nriki                  0.000000\nrubick                0.000000\nshadow_demon          0.000000\ngame_type             0.000000\nshredder              0.000000\ntemplar_assassin      0.000000\nskeleton_king         0.000000\nslardar               0.000000\nslark                 0.000000\nspectre               0.000000\nphantom_assassin      0.000000\noracle                0.000000\nnyx_assassin          0.000000\nnevermore             0.000000\nnecrolyte             0.000000\nmeepo                 0.000000\nmedusa                0.000000\nlycan                 0.000000\nluna                  0.000000\nlion                  0.000000\nlina                  0.000000\ntidehunter            0.000000\nstorm_spirit          0.000000\ntinker                0.000000\njuggernaut            0.000000\njakiro                0.000000\ninvoker               0.000000\nleshrac               0.000000\nLength: 116, dtype: float64\n"}]},"apps":[],"jobName":"paragraph_1524171025049_2117618090","id":"20180419-165025_1635465409","dateCreated":"2018-04-19T16:50:25-0400","dateStarted":"2018-04-19T16:58:27-0400","dateFinished":"2018-04-19T16:58:27-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8349"},{"text":"%md\n\nPySpark trained models can be saved for later use and then reloaded. Conceptually, this is much like pickling, except the output is a directory.","user":"anonymous","dateUpdated":"2018-04-19T16:50:45-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>PySpark trained models can be saved for later use and then reloaded. Conceptually, this is much like pickling, except the output is a directory.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1524171033130_-1100806459","id":"20180419-165033_1375681707","dateCreated":"2018-04-19T16:50:33-0400","dateStarted":"2018-04-19T16:50:45-0400","dateFinished":"2018-04-19T16:50:45-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8350"},{"text":"%pyspark\n\n# SAVE MODEL\n\n#model_output_name = 'gbt_model_pipeline_crossval'\n\n# models will not overwrite existing ones of the same name\n#import shutil\n#if os.path.exists(model_output_name):\n#    shutil.rmtree(model_output_name)\n\n#best_gbt_model.save(model_output_name)","user":"anonymous","dateUpdated":"2018-04-19T16:51:02-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524171045319_1951806638","id":"20180419-165045_348797888","dateCreated":"2018-04-19T16:50:45-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:8351"},{"text":"%md\n\nNow the model can be loaded here or in other analysis. Note that we have to import the model instance to load the file. Previously, we had only imported the classifier.","user":"anonymous","dateUpdated":"2018-04-19T16:51:19-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p>Now the model can be loaded here or in other analysis. Note that we have to import the model instance to load the file. Previously, we had only imported the classifier.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1524171075528_60427018","id":"20180419-165115_1846326396","dateCreated":"2018-04-19T16:51:15-0400","dateStarted":"2018-04-19T16:51:19-0400","dateFinished":"2018-04-19T16:51:19-0400","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:8352"},{"text":"%pyspark\n\n# LOAD MODEL\n\n#from pyspark.ml.classification import GBTClassificationModel\n\n#reloaded_model = GBTClassificationModel.load(model_output_name)\n#reloaded_model","user":"anonymous","dateUpdated":"2018-04-19T16:51:37-0400","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1524171064866_-2002227160","id":"20180419-165104_875514223","dateCreated":"2018-04-19T16:51:04-0400","status":"READY","progressUpdateIntervalMs":500,"$$hashKey":"object:8353"}],"name":"Spark_Machine_Learning","id":"2CX9HRVQD","angularObjects":{"2CZWR1GGK:shared_process":[],"2CZ7856YP:shared_process":[],"2CX8JPHEF:shared_process":[],"2D186B2WU:shared_process":[],"2CY5HAT7D:shared_process":[],"2CZB79PJH:shared_process":[],"2CYFPK9UY:shared_process":[],"2CZPQ5RPQ:shared_process":[],"2CYH9N1YV:shared_process":[],"2CYCTCHVJ:shared_process":[],"2CXPH91QU:shared_process":[],"2CY7DV8BJ:shared_process":[],"2CZ846CKC:shared_process":[],"2CZ5JZ2DK:shared_process":[],"2CZ9C6XMZ:shared_process":[],"2D1TA5NMG:shared_process":[],"2CYEN6EZN:shared_process":[],"2CXA6C49M:shared_process":[],"2CY7EH4R3:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}