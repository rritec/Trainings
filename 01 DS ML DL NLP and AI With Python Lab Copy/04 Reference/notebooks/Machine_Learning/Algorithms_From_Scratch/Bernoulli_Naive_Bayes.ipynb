{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is my from scratch implementation of **Bernoulli Naive Bayes**. \n",
    "\n",
    "Note that the model currently only handles **binary classification**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_rows=10, n_cols=2, probs=(0.5, 0.5), seed=None):\n",
    "    '''\n",
    "    creates a 2D numpy array with 0s and 1s for columns\n",
    "    \n",
    "    INPUT:\n",
    "        n_rows = (int) number of rows in dataset\n",
    "        n_cols = (int) number of columns starting with target followed by features\n",
    "        prob = (tuple) probability of success for target, feature 1, feature 2, ..., feature n\n",
    "    OUTPUT:\n",
    "        dataset (numpy array)\n",
    "    '''\n",
    "    # error handling\n",
    "    assert type(n_rows) == int, 'n_rows must be an integer'\n",
    "    assert type(n_cols) == int, 'n_cols must be an integer'\n",
    "    assert type(probs) == tuple, 'prob must be a tuple of probabilities'\n",
    "    assert len(probs) == n_cols, 'tuple must contain probabilities for each n_col'\n",
    "    assert type(seed) == int, 'seed must be an integer'\n",
    "    \n",
    "    # reproducibility\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "    # create dataset\n",
    "    for i, prob in enumerate(probs):\n",
    "        if i < 1:\n",
    "            dataset = np.random.binomial(n=1, p=prob, size=n_rows)\n",
    "        else:\n",
    "            column = np.random.binomial(n=1, p=prob, size=n_rows)\n",
    "            dataset = np.c_[dataset, column]\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = (0.3, 0.5, 0.2, 0.5)\n",
    "data = create_dataset(n_rows=4000, n_cols=4, probs=probabilities, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 1, 1],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:, 1:]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BernoulliNB:\n",
    "    '''Bernoulli Naive Bayes for binary classification only.'''\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.class_one_prior_ = None\n",
    "        self.class_zero_prior_ = None\n",
    "        self.likelihoods_ = None\n",
    "     \n",
    "    \n",
    "    def _reshape(self, X):\n",
    "        '''converts array to appropriate dimensions'''\n",
    "        try:\n",
    "            self._n_cols = X.shape[1]\n",
    "        except:\n",
    "            self._n_cols = X.reshape(-1,1)\n",
    "        return self._n_cols\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, laplace_smoothing=True):\n",
    "        '''calculate priors and likelihoods'''\n",
    "        # setup\n",
    "        n_bins = 2\n",
    "        self._n_cols = self._reshape(X)\n",
    "        self.likelihoods_ = np.zeros((n_bins, self._n_cols), dtype=float)\n",
    "        \n",
    "        # priors (target)\n",
    "        self.class_one_prior_ = np.mean(y)\n",
    "        self.class_zero_prior_ = 1 - self.class_one_prior_\n",
    "        \n",
    "        # additive smoothing\n",
    "        if laplace_smoothing:\n",
    "            numerator = 1\n",
    "            denominator = len(X)\n",
    "        else:\n",
    "            numerator = 0\n",
    "            denominator = 1\n",
    "\n",
    "        # calculate likelihood matrix\n",
    "        for i in range(n_bins):\n",
    "            for j in range(self._n_cols):\n",
    "                column = X[:,j]\n",
    "                y_intersect_col = np.logical_and(y==i, column==i)\n",
    "                y_intersect_col = sum(y_intersect_col)\n",
    "                sum_y = sum(y==i)\n",
    "                self.likelihoods_[i,j] = (y_intersect_col) / (sum_y) + numerator/denominator\n",
    "        \n",
    "        # find likelihood matrix complements\n",
    "        prob_complements = 1 - self.likelihoods_\n",
    "        self.likelihoods_ = np.concatenate((self.likelihoods_, prob_complements), axis=0)\n",
    "        # reorder likelihood matrix\n",
    "        self.likelihoods_ = self.likelihoods_[[0,2,3,1],:]\n",
    "    \n",
    "    \n",
    "    def predict(self, X, return_probs=True):\n",
    "        '''return most likely class'''\n",
    "        \n",
    "        # error checking\n",
    "        assert type(X) == type(np.array([])), \"X must be a numpy ndarray!\"\n",
    "        \n",
    "        # setup\n",
    "        try: \n",
    "            n_cols = X.shape[1] \n",
    "            n_rows = X.shape[0]\n",
    "        except: \n",
    "            n_cols = X.shape[0]\n",
    "            n_rows = int(len(X) / n_cols)\n",
    "        assert n_cols == self._n_cols, \"number of columns in X don't match those in the training set!\"\n",
    "        \n",
    "        # more setup\n",
    "        predictions = np.zeros((n_rows,1), dtype=int)\n",
    "        probs = []\n",
    "        class_zero_probs,  class_one_probs = np.split(self.likelihoods_, 2)\n",
    "        \n",
    "        # main logic\n",
    "        for i in range(n_rows):\n",
    "            # likelihoods\n",
    "            observation = X[i]\n",
    "            class_zero_likelihoods = class_zero_probs[observation, np.arange(self._n_cols)]\n",
    "            class_one_likelihoods = class_one_probs[observation, np.arange(self._n_cols)]\n",
    "            \n",
    "            # posteriors\n",
    "            class_zero_posterior = self.class_zero_prior_ * np.prod(class_zero_likelihoods)\n",
    "            class_one_posterior = self.class_one_prior_ * np.prod(class_one_likelihoods)\n",
    "            probs.append((class_zero_posterior, class_one_posterior))\n",
    "            \n",
    "            # save predictions for outputting\n",
    "            if n_rows == 1:\n",
    "                predictions = np.argmax((class_zero_posterior, class_one_posterior))\n",
    "            else:\n",
    "                predictions[i] = np.argmax((class_zero_posterior, class_one_posterior))\n",
    "            \n",
    "        # whether to return tuple of probabilities    \n",
    "        if return_probs:\n",
    "            return probs, predictions\n",
    "        else:\n",
    "            return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50682661,  0.79619739,  0.51713589],\n",
       "       [ 0.49317339,  0.20380261,  0.48286411],\n",
       "       [ 0.52544503,  0.81103896,  0.48163711],\n",
       "       [ 0.47455497,  0.18896104,  0.51836289]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = BernoulliNB()\n",
    "nb.fit(X, y, laplace_smoothing=True)\n",
    "nb.likelihoods_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.50657661,  0.79594739,  0.51688589],\n",
       "       [ 0.49342339,  0.20405261,  0.48311411],\n",
       "       [ 0.52569503,  0.81128896,  0.48188711],\n",
       "       [ 0.47430497,  0.18871104,  0.51811289]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_smooth = BernoulliNB()\n",
    "nb_smooth.fit(X, y, laplace_smoothing=False)\n",
    "nb_smooth.likelihoods_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_d = np.array([0,0,0])\n",
    "one_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_d = np.array([0,0,0,1,1,1]).reshape(2,-1)\n",
    "two_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.14675556313974908, 0.0609087486122162)], 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(one_d, return_probs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0.14656622722773208, 0.060988152329824151)], 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_smooth.predict(one_d, return_probs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Array - No Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(two_d, return_probs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(class 0) =    0.1468 | P(class=1) =   0.06091 | Prediction = 0\n",
      "P(class 0) =   0.03413 | P(class=1) =   0.01379 | Prediction = 0\n"
     ]
    }
   ],
   "source": [
    "probs, predictions = nb.predict(two_d)\n",
    "for prob, prediction in zip(probs, predictions):\n",
    "    print('P(class 0) = {:9.4} | P(class=1) = {:9.4} | Prediction = {}'.format(prob[0], prob[1], prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D Array - Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_smooth.predict(two_d, return_probs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(class 0) =   0.1466 | P(class=1) =  0.06099 | Prediction = 0\n",
      "P(class 0) =  0.03421 | P(class=1) =  0.01376 | Prediction = 0\n"
     ]
    }
   ],
   "source": [
    "probs, predictions = nb_smooth.predict(two_d)\n",
    "for prob, prediction in zip(probs, predictions):\n",
    "    print('P(class 0) = {:8.4} | P(class=1) = {:8.4} | Prediction = {}'.format(prob[0], prob[1], prediction[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions for Future Work\n",
    "\n",
    "1. Log transform probabilities to handle underflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
