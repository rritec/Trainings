{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegression:\n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self._fit_intercept = fit_intercept\n",
    "\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit model coefficients.\n",
    "\n",
    "        Arguments:\n",
    "        X: 1D or 2D numpy array \n",
    "        y: 1D numpy array\n",
    "        \"\"\"\n",
    "        \n",
    "        # check if X is 1D or 2D array\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1,1)\n",
    "            \n",
    "        # add bias if fit_intercept\n",
    "        if self._fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        # closed form solution\n",
    "        xTx = np.dot(X.T, X)\n",
    "        inverse_xTx = np.linalg.inv(xTx)\n",
    "        xTy = np.dot(X.T, y)\n",
    "        coef = np.dot(inverse_xTx, xTy)\n",
    "        \n",
    "        # set attributes\n",
    "        if self._fit_intercept:\n",
    "            self.intercept_ = coef[0]\n",
    "            self.coef_ = coef[1:]\n",
    "        else:\n",
    "            self.intercept_ = 0\n",
    "            self.coef_ = coef\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"Output model prediction.\n",
    "\n",
    "        Arguments:\n",
    "        X: 1D or 2D numpy array \n",
    "        \"\"\"\n",
    "        # check if X is 1D or 2D array\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1,1) \n",
    "        return np.dot(X, self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    \n",
    "    def __init__(self, X, y, model):\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        self.model = model\n",
    "        # degrees of freedom population dep. variable variance\n",
    "        self._dft = X.shape[0] - 1   \n",
    "        # degrees of freedom population error variance\n",
    "        self._dfe = X.shape[0] - X.shape[1] - 1  \n",
    "    \n",
    "    def sse(self):\n",
    "        '''returns sum of squared errors (model vs actual)'''\n",
    "        squared_errors = (self.target - self.model.predict(self.data)) ** 2\n",
    "        self.sq_error_ = np.sum(squared_errors)\n",
    "        return self.sq_error_\n",
    "        \n",
    "    def sst(self):\n",
    "        '''returns total sum of squared errors (actual vs avg(actual))'''\n",
    "        avg_y = np.mean(self.target)\n",
    "        squared_errors = (self.target - avg_y) ** 2\n",
    "        self.sst_ = np.sum(squared_errors)\n",
    "        return self.sst_\n",
    "    \n",
    "    def r_squared(self):\n",
    "        '''returns calculated value of r^2'''\n",
    "        self.r_sq_ = 1 - self.sse()/self.sst()\n",
    "        return self.r_sq_\n",
    "    \n",
    "    def adj_r_squared(self):\n",
    "        '''returns calculated value of adjusted r^2'''\n",
    "        self.adj_r_sq_ = 1 - (self.sse()/self._dfe) / (self.sst()/self._dft)\n",
    "        return self.adj_r_sq_\n",
    "    \n",
    "    def mse(self):\n",
    "        '''returns calculated value of mse'''\n",
    "        self.mse_ = np.mean( (self.model.predict(self.data) - self.target) ** 2 )\n",
    "        return self.mse_\n",
    "    \n",
    "    def pretty_print_stats(self):\n",
    "        '''returns report of statistics for a given model object'''\n",
    "        items = ( ('sse:', self.sse()), ('sst:', self.sst()), \n",
    "                 ('mse:', self.mse()), ('r^2:', self.r_squared()), \n",
    "                  ('adj_r^2:', self.adj_r_squared()))\n",
    "        for item in items:\n",
    "            print('{0:8} {1:.4f}'.format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()\n",
    "data = boston.data\n",
    "target = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn\n",
    "lr = LinearRegression()\n",
    "lr.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scratch\n",
    "mlr = MyLinearRegression()\n",
    "mlr.fit(data, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse: 21.8978\n",
      "r^2 0.7406\n"
     ]
    }
   ],
   "source": [
    "print('mse:', round(mean_squared_error(target, lr.predict(data)), 4))\n",
    "print('r^2', round(r2_score(target, lr.predict(data)), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:     11080.2763\n",
      "sst:     42716.2954\n",
      "mse:     21.8978\n",
      "r^2:     0.7406\n",
      "adj_r^2: 0.7338\n"
     ]
    }
   ],
   "source": [
    "metrics = Metrics(data, target, mlr)\n",
    "metrics.pretty_print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right now we have two separate classes. We'd like to integrate them but how do we do that? \n",
    "\n",
    "## -- INHERITANCE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedMetrics:\n",
    "    \n",
    "    def sse(self):\n",
    "        '''returns sum of squared errors (model vs actual)'''\n",
    "        squared_errors = (self.target - self.predict(self.data)) ** 2\n",
    "        self.sq_error_ = np.sum(squared_errors)\n",
    "        return self.sq_error_\n",
    "        \n",
    "    def sst(self):\n",
    "        '''returns total sum of squared errors (actual vs avg(actual))'''\n",
    "        avg_y = np.mean(self.target)\n",
    "        squared_errors = (self.target - avg_y) ** 2\n",
    "        self.sst_ = np.sum(squared_errors)\n",
    "        return self.sst_\n",
    "    \n",
    "    def r_squared(self):\n",
    "        '''returns calculated value of r^2'''\n",
    "        self.r_sq_ = 1 - self.sse()/self.sst()\n",
    "        return self.r_sq_\n",
    "    \n",
    "    def adj_r_squared(self):\n",
    "        '''returns calculated value of adjusted r^2'''\n",
    "        self.adj_r_sq_ = 1 - (self.sse()/self._dfe) / (self.sst()/self._dft)\n",
    "        return self.adj_r_sq_\n",
    "    \n",
    "    def mse(self):\n",
    "        '''returns calculated value of mse'''\n",
    "        self.mse_ = np.mean( (self.predict(self.data) - self.target) ** 2 )\n",
    "        return self.mse_\n",
    "    \n",
    "    def pretty_print_stats(self):\n",
    "        '''returns report of statistics for a given model object'''\n",
    "        items = ( ('sse:', self.sse()), ('sst:', self.sst()), \n",
    "                 ('mse:', self.mse()), ('r^2:', self.r_squared()), \n",
    "                  ('adj_r^2:', self.adj_r_squared()))\n",
    "        for item in items:\n",
    "            print('{0:8} {1:.4f}'.format(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinearRegressionWithInheritance(ModifiedMetrics):\n",
    "    \n",
    "    \n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        self._fit_intercept = fit_intercept\n",
    "          \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit model coefficients.\n",
    "\n",
    "        Arguments:\n",
    "        X: 1D or 2D numpy array \n",
    "        y: 1D numpy array\n",
    "        \"\"\"\n",
    "        \n",
    "        # training data & ground truth data\n",
    "        self.data = X\n",
    "        self.target = y\n",
    "        \n",
    "        # degrees of freedom population dep. variable variance \n",
    "        self._dft = X.shape[0] - 1  \n",
    "        # degrees of freedom population error variance\n",
    "        self._dfe = X.shape[0] - X.shape[1] - 1\n",
    "        \n",
    "        # check if X is 1D or 2D array\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1,1)\n",
    "            \n",
    "        # add bias if fit_intercept\n",
    "        if self._fit_intercept:\n",
    "            X = np.c_[np.ones(X.shape[0]), X]\n",
    "        \n",
    "        # closed form solution\n",
    "        xTx = np.dot(X.T, X)\n",
    "        inverse_xTx = np.linalg.inv(xTx)\n",
    "        xTy = np.dot(X.T, y)\n",
    "        coef = np.dot(inverse_xTx, xTy)\n",
    "        \n",
    "        # set attributes\n",
    "        if self._fit_intercept:\n",
    "            self.intercept_ = coef[0]\n",
    "            self.coef_ = coef[1:]\n",
    "        else:\n",
    "            self.intercept_ = 0\n",
    "            self.coef_ = coef\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"Output model prediction.\n",
    "\n",
    "        Arguments:\n",
    "        X: 1D or 2D numpy array \n",
    "        \"\"\"\n",
    "        # check if X is 1D or 2D array\n",
    "        if len(X.shape) == 1:\n",
    "            X = X.reshape(-1,1) \n",
    "        return np.dot(X, self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scratch w/inheritance\n",
    "mlri = MyLinearRegressionWithInheritance()\n",
    "mlri.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sse:     11080.2763\n",
      "sst:     42716.2954\n",
      "mse:     21.8978\n",
      "r^2:     0.7406\n",
      "adj_r^2: 0.7338\n"
     ]
    }
   ],
   "source": [
    "mlri.pretty_print_stats()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
