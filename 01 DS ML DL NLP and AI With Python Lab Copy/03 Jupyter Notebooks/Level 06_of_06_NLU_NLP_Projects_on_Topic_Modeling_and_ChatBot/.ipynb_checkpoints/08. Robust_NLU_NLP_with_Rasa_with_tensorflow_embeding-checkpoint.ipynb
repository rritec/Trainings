{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust NLU/NLP with Rasa\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Method 1: use base enviornment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rasa NLU Installations\n",
    "- Open anaconda prompt as administrator\n",
    "- run below commands\n",
    "    - <code> conda install python=3.6</code>\n",
    "    - <code> pip install rasa_core</code>\n",
    "    - <code> conda install -c derickl sklearn-crfsuite </code>\n",
    "    - <code> python -m spacy download en </code>\n",
    "    - <code> python -m spacy download en_core_web_sm </code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Method 2: Create Virtual Enviornment\n",
    "- use Anaconda Navigator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. RASA NLU\n",
    "- Language Understanding for chatbots and AI assistants\n",
    "- Library for intent recognition & entity extraction\n",
    "- Based on spaCy, scikit-learn,tensorflow & other libraries\n",
    "- [Refer the official Document](https://rasa.com/docs/nlu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore below sites\n",
    "- [Google Product dialogflow](https://dialogflow.com/)\n",
    "- [Microsoft Product Luis](https://www.luis.ai/)\n",
    "- [Facebook Product wit](https://wit.ai/)\n",
    "- To Migrate Product from above products to rasa [explore](https://nlu.rasa.com/migrating.html#section-migration)\n",
    "- To prepare Intents,Training Examples and Enities use [Rasa nlu trainer](https://rasahq.github.io/rasa-nlu-trainer/)\n",
    "- Note: If you need parse json use [Online link](http://json.parser.online.fr/) or notepad++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exercise 1:Rasa NLU \n",
    "- Please note that iam using below versions.If you are using any other versions, some of the functions may not work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "rasa-core                 0.13.7                   pypi_0    pypi\n",
      "rasa-core-sdk             0.12.2                   pypi_0    pypi\n",
      "rasa-nlu                  0.14.6                   pypi_0    pypi\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list rasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "tensorboard               1.12.2                   pypi_0    pypi\n",
      "tensorflow                1.12.0                   pypi_0    pypi\n",
      "tensorflow-base           1.13.1          mkl_py36hcaf7020_0    anaconda\n",
      "tensorflow-estimator      1.13.0                     py_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "sklearn-crfsuite          0.3.6                      py_0    derickl\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list skl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\ProgramData\\Anaconda3:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "spacy                     2.0.12           py36h8300f20_0  \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda list spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this exercise you'll use Rasa NLU to create an [interpreter](https://en.wikipedia.org/wiki/Interpreter_(computing)), which parses incoming user messages and returns a set of entities. \n",
    "- Your job is to train an interpreter using the [MITIE](https://github.com/mit-nlp/MITIE) entity recognition model in rasa NLU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.training_data import load_data\n",
    "from rasa_nlu.config import RasaNLUModelConfig\n",
    "from rasa_nlu.model import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Create Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create args dictionary\n",
    "args = {\"pipeline\": \"spacy_sklearn\"}\n",
    "# Create a configuration and trainer\n",
    "config = RasaNLUModelConfig(configuration_values=args)\n",
    "trainer = Trainer(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Prepare Intents, Training Examples and Entities\n",
    "- [Open RASA NLU Trainer](https://rasahq.github.io/rasa-nlu-trainer/)\n",
    "- Did you understand how to add Intents / training examples / Entities?\n",
    "- Did you understand sample data? How many Intents are there in sample data?\n",
    "\n",
    "    - <input type=\"radio\" disabled> One\n",
    "    - <input type=\"radio\" disabled> Two\n",
    "    - <input type=\"radio\" disabled> Three\n",
    "    - <input type=\"radio\" disabled checked> Four "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Load Training Data\n",
    "- Download Training data from [RASA NLU Trainier](https://rasahq.github.io/rasa-nlu-trainer/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "training_data = load_data(\"C:\\\\Users\\\\Hi\\\\Google Drive\\\\01 DS ML DL NLP and AI With Python Lab Copy\\\\02 Lab Data\\\\Python\\\\testData.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Create Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# Create an interpreter by training the model\n",
    "interpreter = trainer.train(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"restaurant_search\",\n",
      "    \"confidence\": 0.8117546021296682\n",
      "  },\n",
      "  \"entities\": [\n",
      "    {\n",
      "      \"start\": 18,\n",
      "      \"end\": 25,\n",
      "      \"value\": \"mexican\",\n",
      "      \"entity\": \"cuisine\",\n",
      "      \"confidence\": 0.7098588870914954,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    },\n",
      "    {\n",
      "      \"start\": 44,\n",
      "      \"end\": 49,\n",
      "      \"value\": \"north\",\n",
      "      \"entity\": \"location\",\n",
      "      \"confidence\": 0.8034438501034744,\n",
      "      \"extractor\": \"ner_crf\"\n",
      "    }\n",
      "  ],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"restaurant_search\",\n",
      "      \"confidence\": 0.8117546021296682\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"affirm\",\n",
      "      \"confidence\": 0.07632370084271999\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"goodbye\",\n",
      "      \"confidence\": 0.07320244480921605\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"greet\",\n",
      "      \"confidence\": 0.03871925221839578\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"I'm looking for a Mexican restaurant in the North of town\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Try it out\n",
    "import json\n",
    "print(json.dumps(interpreter.parse(\"I'm looking for a Mexican restaurant in the North of town\"), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
